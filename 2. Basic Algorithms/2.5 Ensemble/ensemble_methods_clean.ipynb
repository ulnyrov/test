{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ЗАНЯТИЕ 2.5. АНСАМБЛИ МОДЕЛЕЙ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "#устраним ошибки со шрифтами\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = ['DejaVu Sans']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 1. Бэггинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание задачи\n",
    "\n",
    "Используем данные страхового подразделения BNP Paribas из соревнования\n",
    "\n",
    "https://www.kaggle.com/c/bnp-paribas-cardif-claims-management\n",
    "\n",
    "Решается задача классификации страховых случаев:\n",
    "    1. Случаи, требующие дополнительных документов для подтвердения (0)\n",
    "    2. Случаи, которые можно подтверждать автоматически на основе имеющейся информации (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уменьшим размер данных для ускорения обучения, возмем случайную подвыборку 20% данных со стратификацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "random_splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=777)\n",
    "\n",
    "for train_index, test_index in random_splitter.split(data, data.target):\n",
    "    data = data.iloc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиение на обучение и hold-out тест 70/30. Данных достаточно много, поэтому можно принебречь честной кросс-валидацией и оценивать модель на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=777)\n",
    "\n",
    "for train_index, test_index in splitter.split(data, data.target):\n",
    "    d_train = data.iloc[train_index]\n",
    "    d_test = data.iloc[test_index]\n",
    "    \n",
    "    y_train = data['target'].iloc[train_index]\n",
    "    y_test = data['target'].iloc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Первичный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размер датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распределение значений таргета (event rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.target.value_counts() / len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Находим категориальные признаки\n",
    "\n",
    "Чтобы в разы не увеличивать число признаков при построении dummy, будем использовать категориальные признаки с < 30 уникальных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat = list(data.dtypes[data.dtypes == object].index)\n",
    "\n",
    "#закодируем пропущенные значений строкой, факт пропущенного значения тоже может нести в себе информацию\n",
    "data[cat_feat] = data[cat_feat].fillna('nan')\n",
    "\n",
    "#отфильтруем непрерывные признаки\n",
    "num_feat = [f for f in data if f not in (cat_feat + ['ID', 'target'])]\n",
    "\n",
    "cat_nunique = d_train[cat_feat].nunique()\n",
    "print(cat_nunique)\n",
    "cat_feat = list(cat_nunique[cat_nunique < 30].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Композиции моделей одного семейства"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Будем использовать решающие деревья\n",
    "\n",
    "1. Неустойчивы к входным данным\n",
    "2. Склонны к переобучению\n",
    "3. Быстро обучаются\n",
    "\n",
    "=> отличный выбор для построения композиций\n",
    "\n",
    "**Создаем признаки для \"деревянных\" моделей**\n",
    "\n",
    "1. Заменяем пропуски на специальное значение -999, чтобы деревья могли их отличить\n",
    "3. Создаем дамми-переменные для категорий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_train = pd.get_dummies(d_train[cat_feat], columns=cat_feat)\n",
    "dummy_test = pd.get_dummies(d_test[cat_feat], columns=cat_feat)\n",
    "\n",
    "dummy_cols = list(set(dummy_train) & set(dummy_test))\n",
    "\n",
    "dummy_train = dummy_train[dummy_cols]\n",
    "dummy_test = dummy_test[dummy_cols]\n",
    "\n",
    "\n",
    "X_train = pd.concat([d_train[num_feat].fillna(-999),\n",
    "                     dummy_train], axis=1)\n",
    "\n",
    "X_test = pd.concat([d_test[num_feat].fillna(-999),\n",
    "                     dummy_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем решающее дерево\n",
    "\n",
    "Немного ограничим глубину и минимальное кол-во объектов в листе для уменьшения переобучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_tree = DecisionTreeClassifier(max_depth=15, min_samples_leaf=20)\n",
    "clf_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Считаем ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_auc(y, y_pred, plot_label='', prin=True):\n",
    "    fpr, tpr, _ = roc_curve(y, y_pred)\n",
    "    auc_val = auc(fpr, tpr)\n",
    "    if prin:\n",
    "        print('ROC AUC: {0:.4f}'.format(auc_val))\n",
    "    if plot_label:\n",
    "        plt.plot(fpr, tpr, label=plot_label)\n",
    "        plt.xlabel('FPR')\n",
    "        plt.ylabel('TPR')\n",
    "    return auc_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказываем вероятность класса 1 и считаем ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = clf_tree.predict_proba(X_test)[:, 1]\n",
    "y_pred_train = clf_tree.predict_proba(X_train)[:, 1]\n",
    "\n",
    "print('Train:')\n",
    "calc_auc(y_train, y_pred_train, 'train')\n",
    "print('Test:')\n",
    "calc_auc(y_test, y_pred_test, 'test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Бэггинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самостоятельная реализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAGGING_ITERS = 20\n",
    "\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train:')\n",
    "calc_auc(y_train, y_pred_train, 'train')\n",
    "print('Test:')\n",
    "calc_auc(y_test, y_pred_test, 'test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Другой способ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем готовый алгоритм из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(n_estimators=20, base_estimator=clf_tree, n_jobs=-1)\n",
    "bag_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = bag_clf.predict_proba(X_test)[:, 1]\n",
    "y_pred_train = bag_clf.predict_proba(X_train)[:, 1]\n",
    "\n",
    "print('Train:')\n",
    "calc_auc(y_train, y_pred_train, 'train')\n",
    "print('Test:')\n",
    "calc_auc(y_test, y_pred_test, 'test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 2. Случайный лес\n",
    "\n",
    "Бэггинг + случайные подпространства = случайный лес\n",
    "\n",
    "**Важные гиперпараметры алгоритма**\n",
    "\n",
    "a. Параметры деревьев\n",
    "    1. criterion - критерий построения дерева\n",
    "    2. max_depth - максимальная глубина дерева (обычно 10-20, больше глубина -> больше риск переобучения)\n",
    "    3. min_samples_leaf - минимальное число объектов в листе (обычно 20+, больше объектов -> меньше риск переобучения)\n",
    "\n",
    "b. Параметры леса\n",
    "    1. n_estimators - кол-во деревьев (чем больше тем лучше)\n",
    "    2. max_features - число признаков случайного подпространства\n",
    "    3. bootstrap - использовать ли бэггинг\n",
    "    4. n_jobs - кол-во потоков для одновременного построения деревьев (большая прибавка к скорости на многоядерных процах)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'минимальное число объектов в листе'.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=100, max_depth=15, min_samples_leaf=20, max_features=0.8, n_jobs=-1)\n",
    "\n",
    "clf_rf.fit(X_train, y_train)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_test = clf_rf.predict_proba(X_test)[:, 1]\n",
    "y_pred_rf_train = clf_rf.predict_proba(X_train)[:, 1]\n",
    "\n",
    "print('Train:')\n",
    "calc_auc(y_train, y_pred_train, 'train')\n",
    "print('Test:')\n",
    "calc_auc(y_test, y_pred_test, 'test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Важность признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В sklearn - усредненное по всем деревьям в ансамбле кол-во сплитов по признаку, взвешенное на прирост информации (Information gain) и долю объектов в вершине, в которой производится этот сплит\n",
    "\n",
    "Это не единственный вариант, см здесь:\n",
    "\n",
    "https://medium.com/@ceshine/feature-importance-measures-for-tree-models-part-i-47f187c1a2c3\n",
    "\n",
    "Важности признаков случайного леса лежат в артибуте **feature\\_importances\\_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imp = pd.Series(clf_rf.feature_importances_, index=X_train.columns)\n",
    "imp.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 3. Композиции моделей разных типов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейная комбинация моделей разного типа\n",
    "\n",
    "Смешаем дерево и логистическую регрессию\n",
    "\n",
    "**Создаем признаки для лог регрессии**\n",
    "\n",
    "1. Заменяем пропуски на медианы\n",
    "2. Создаем индикаторы пропущенных значений\n",
    "3. Создаем дамми-переменные для категорий\n",
    "4. Нормируем признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train_median = d_train[num_feat].median()\n",
    "\n",
    "X_train_lin = pd.concat([d_train[num_feat].fillna(train_median),\n",
    "                     d_train[num_feat + cat_feat].isnull().astype(np.int8).add_suffix('_NaN'),\n",
    "                     dummy_train], axis=1)\n",
    "\n",
    "X_test_lin = pd.concat([d_test[num_feat].fillna(train_median),\n",
    "                     d_test[num_feat + cat_feat].isnull().astype(np.int8).add_suffix('_NaN'),\n",
    "                     dummy_test], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_lin[num_feat])\n",
    "\n",
    "X_train_lin[num_feat] = scaler.transform(X_train_lin[num_feat])\n",
    "X_test_lin[num_feat] = scaler.transform(X_test_lin[num_feat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим логистическую регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr = LogisticRegression(penalty='l1', C=0.1)\n",
    "\n",
    "clf_lr.fit(X_train_lin, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lin_test = clf_lr.predict_proba(X_test_lin)[:, 1]\n",
    "y_pred_lin_train = clf_lr.predict_proba(X_train_lin)[:, 1]\n",
    "\n",
    "print('Train:')\n",
    "calc_auc(y_train, y_pred_lin_train, 'train')\n",
    "print('Test:')\n",
    "calc_auc(y_test, y_pred_lin_test, 'test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем строить линейную комбинацию вида\n",
    "\n",
    "$y = \\alpha y_1 + (1 - \\alpha) y_2$\n",
    "\n",
    "Параметр $\\alpha$ переберем по сетке от 0 до 1, оценивая качество на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs = []\n",
    "alpha_space = np.linspace(0, 1, 100)\n",
    "for alpha in alpha_space:\n",
    "    y_pred_weight = alpha * y_pred_lin_test + (1 - alpha) * y_pred_rf_test\n",
    "    aucs.append(calc_auc(y_test, y_pred_weight, prin=False))\n",
    "aucs = np.array(aucs)    \n",
    "\n",
    "max_ind = np.where(aucs == aucs.max())[0]\n",
    "alpha = alpha_space[max_ind]\n",
    "\n",
    "plt.plot(alpha_space, aucs)\n",
    "plt.plot(alpha_space[max_ind], aucs[max_ind], 'o', c='r')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('auc')\n",
    "\n",
    "#итоговое взвешенное предсказание\n",
    "y_pred_weight = alpha * y_pred_lin_test + (1 - alpha) * y_pred_rf_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним 3 метода (приблизим график ROC кривой, чтобы увидеть разницу)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Weighted:')\n",
    "calc_auc(y_test, y_pred_weight, 'weighted')\n",
    "print('Log regression:')\n",
    "calc_auc(y_test, y_pred_lin_test, 'LR')\n",
    "print('Random forest:')\n",
    "calc_auc(y_test, y_pred_rf_test, 'RF')\n",
    "plt.legend();\n",
    "plt.xlim(0.2, 0.5)\n",
    "plt.ylim(0.5, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стэкинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Средние значения таргета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим новые признаки, на основе категориальных переменных. Каждому уникальному значению $V$ переменной $X_i$ сопоставим среднее значение таргета среди всех объектов, у которых переменная $X_i$ принимает значение $V$ \n",
    "\n",
    "Новый признак со средними значением таргета в категории можно считать за предсказание вер-ти класса 1 простого классификатора \"усреднения\"\n",
    "\n",
    "Опишем класс этого классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MeanClassifier():\n",
    "    def __init__(self, col):\n",
    "        self._col = col\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self._y_mean = y.mean()\n",
    "        self._means = y.groupby(X[self._col].astype(str)).mean()\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        new_feature = X[self._col].astype(str)\\\n",
    "            .map(self._means.to_dict())\\\n",
    "            .fillna(self._y_mean)\n",
    "        return np.stack([1-new_feature, new_feature], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем предсказания по фолдам кросс-валидации. **Главное не допустить утечки информации!**\n",
    "\n",
    "Опишем функцию для стекинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_meta_features(clf, X_train, y_train, X_test, stack_cv):\n",
    "    meta_train = np.zeros_like(y_train, dtype=float)\n",
    "    meta_test = np.zeros_like(y_test, dtype=float)\n",
    "    \n",
    "    for i, (train_ind, test_ind) in enumerate(stack_cv.split(X_train, y_train)):\n",
    "        \n",
    "        clf.fit(X_train.iloc[train_ind], y_train.iloc[train_ind])\n",
    "        meta_train[test_ind] = clf.predict_proba(X_train.iloc[test_ind])[:, 1]\n",
    "        meta_test += clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    return meta_train, meta_test / stack_cv.n_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стекинг нескольких моделей\n",
    "0. Средние значения\n",
    "1. Random Forest\n",
    "2. Log reg\n",
    "3. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, какое качество дает линейный SVM\n",
    "\n",
    "для совместимости с общим кодом стекинга немного модифицируем класс SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def norm(x):\n",
    "    return (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "class SVMWrapper(LinearSVC):\n",
    "    def predict_proba(self, X):\n",
    "        df = norm(self.decision_function(X))\n",
    "        return np.stack([1-df, df], axis=1)\n",
    "\n",
    "clf_svm = SVMWrapper(C=0.001)    \n",
    "clf_svm.fit(X_train_lin, y_train)\n",
    "\n",
    "y_pred_svm_test = clf_svm.predict_proba(X_test_lin)[:, 1]\n",
    "y_pred_svm_train = clf_svm.predict_proba(X_train_lin)[:, 1]\n",
    "\n",
    "print('Train:')\n",
    "calc_auc(y_train, y_pred_lin_train, 'train')\n",
    "print('Test:')\n",
    "calc_auc(y_test, y_pred_lin_test, 'test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь получим мета признаки для 3х моделей:\n",
    "* SVM\n",
    "* Logreg\n",
    "* Random Forest\n",
    "и средних значений по каждой категориальной переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "stack_cv = StratifiedKFold(n_splits=10, random_state=555)\n",
    "\n",
    "meta_train = []\n",
    "meta_test = []\n",
    "col_names = []\n",
    "\n",
    "print('mean features...')\n",
    "for c in cat_nunique.index.tolist():\n",
    "    clf = MeanClassifier(c)\n",
    "    \n",
    "    meta_tr, meta_te = get_meta_features(clf, d_train, y_train, d_test, stack_cv)\n",
    "\n",
    "    meta_train.append(meta_tr)\n",
    "    meta_test.append(meta_te)\n",
    "    col_names.append('mean_pred_{}'.format(c))\n",
    "\n",
    "print('SVM features...')\n",
    "meta_tr, meta_te = get_meta_features(clf_svm, X_train_lin, y_train, X_test_lin, stack_cv)\n",
    "\n",
    "meta_train.append(meta_tr)\n",
    "meta_test.append(meta_te)\n",
    "col_names.append('svm_pred')\n",
    "\n",
    "print('LR features...')\n",
    "meta_tr, meta_te = get_meta_features(clf_lr, X_train_lin, y_train, X_test_lin, stack_cv)\n",
    "\n",
    "meta_train.append(meta_tr)\n",
    "meta_test.append(meta_te)\n",
    "col_names.append('lr_pred')\n",
    "\n",
    "print('RF features...')\n",
    "meta_tr, meta_te = get_meta_features(clf_rf, X_train, y_train, X_test, stack_cv)\n",
    "\n",
    "meta_train.append(meta_tr)\n",
    "meta_test.append(meta_te)\n",
    "col_names.append('rf_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_meta_train = pd.DataFrame(np.stack(meta_train, axis=1), columns=col_names)\n",
    "X_meta_test = pd.DataFrame(np.stack(meta_test, axis=1), columns=col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Стэкинг мета-признаков с помощью LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем регуляризованную лог регрессию в качестве алгоритма второго уровня"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr_meta = LogisticRegression(penalty='l2', C=1)\n",
    "\n",
    "clf_lr_meta.fit(X_meta_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_meta_test = clf_lr_meta.predict_proba(X_meta_test)[:, 1]\n",
    "\n",
    "calc_auc(y_test, y_pred_meta_test, 'test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Посмотрим на коэффициенты объединяющей линейной модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим интерпретацию общей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(clf_lr_meta.coef_.flatten(), index=X_meta_train.columns).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашняя работа\n",
    "\n",
    "#### Простая\n",
    "1. Теперь решаем задачу регрессии - предскажем цены на недвижимость. Использовать датасет https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data (train.csv)\n",
    "2. Данных немного, поэтому необходимо использовать 10-fold кросс-валидацию для оценки качества моделей\n",
    "3. Построить случайный лес, вывести важность признаков\n",
    "4. Обучить стекинг как минимум 3х моделей, использовать хотя бы 1 линейную модель и 1 нелинейную\n",
    "5. Для валидации модели 2-го уровня использовать отдельный hold-out датасет, как на занятии\n",
    "6. Показать, что использование ансамблей моделей действительно улучшает качество (стекинг vs другие модели сравнивать на hold-out)\n",
    "7. В качестве решения:\n",
    "    Jupyter notebook с кодом, комментариями и графиками\n",
    "\n",
    "#### Средняя\n",
    "0. Все то же, что и в части 1, плюс:\n",
    "1. Попробовать другие оценки важности переменных, например Boruta\n",
    "http://danielhomola.com/2015/05/08/borutapy-an-all-relevant-feature-selection-method/#comments\n",
    "3. Изучить extremely randomized trees (ExtraTreesRegressor в sklearn), сравнить с Random Forest\n",
    "4. Проводить настройку гиперпараметров для моделей первого уровня в стекинге (перебирать руками и смотреть на CV или по сетке: GridSearchCV, RandomizedSearchCV)\n",
    "5. Попробовать другие алгоритмы второго уровня\n",
    "6. Сделать сабмиты на kaggle (минимум 3: отдельные модели vs стекинг), сравнить качество на локальной валидации и на leaderboard\n",
    "7. В качестве решения:\n",
    "    * Jupyter notebook с кодом, комментариями и графиками\n",
    "    * сабмит на kaggle (ник на leaderboard)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "170px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
