{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Mover's Distance \n",
    "## по статье Matthew J. Kusner'а \"From Word Embeddings to Document Distances\" [1]\n",
    "\n",
    "![img](https://raw.githubusercontent.com/mkusner/wmd/master/fig1.png)\n",
    "\n",
    "\n",
    "Формулировка задачи определения сходства между двумя предложениями как задачи транспортной задачи:\n",
    "\n",
    "1. Пусть $X \\in \\mathbb{R}^{d \\times n}$ – матрица эмбеддингов,  $d$ – размерность эмбеддинга, $n$ - количество слов;\n",
    "2. Вектор-документ в векторной модели: $d \\in \\mathbb{R}^n$ состоит из $c_i = \\texttt{count}(word_i, doc)$\n",
    "3. Нормированный вектор-документ: $d_i = \\frac{c_i}{\\sum_i c_i}$\n",
    "4. Расстояние между словами: $\\texttt{cost}(word_i, word_j) = ||x_i - x_j||_2$\n",
    "\n",
    "Дано два документа, $d, d'$. Пусть  $T \\in \\mathbb{R}^{n \\times n}$, $T_{ij} \\ge 0$ – матрица потока показывает расстояния от каждого слова $d$ до $d'$.\n",
    "\n",
    "Транспортная задача:\n",
    "\n",
    "$\\min_{T \\ge 0} \\sum_{i,j}^n T_{ij}\\texttt{cost}(word_i, word_j) $\n",
    "\n",
    "при условии:\n",
    "\n",
    "$\\sum_{j} T_{ij} = d_i$\n",
    "\n",
    "$\\sum_{i} T_{ij} = d'_j$.\n",
    "\n",
    "Задача решается средствами линейного программирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Примеры "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "start_nb = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем fasttext эмбеддинги Facebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell took 503.74 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "import os\n",
    "\n",
    "from gensim.models import *\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('/NLP/embeddings/wiki.ru.vec', binary=False)\n",
    "\n",
    "print('Cell took %.2f seconds to run.' % (time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычисляем попарное сходство между тремя тестовыми предложениями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance between s1 and s2 = 1.3363\n",
      "distance between s1 and s3 = 2.5128\n",
      "distance between s2 and s3 = 2.5454\n"
     ]
    }
   ],
   "source": [
    "s1 = 'Ученые обнаружили ископаемую ящерицу с парой теменных глаз'\n",
    "s2 = 'У палеогеновой ящерицы нашли вторую пару глаз'\n",
    "s3 = 'Apple через два года откажется от процессоров Intel'\n",
    "\n",
    "distance = model.wmdistance(s1, s2)\n",
    "print ('distance between s1 and s2 = %.4f' % distance)\n",
    "\n",
    "distance = model.wmdistance(s1, s3)\n",
    "print ('distance between s1 and s3 = %.4f' % distance)\n",
    "\n",
    "distance = model.wmdistance(s2, s3)\n",
    "print ('distance between s2 and s3 = %.4f' % distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Вычисляем попарное сходство между тремя тестовыми предложениями с использованием нормированных эмбеддингов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance between s1 and s2 = 0.3252\n",
      "distance between s1 and s3 = 0.5703\n",
      "distance between s2 and s3 = 0.5574\n"
     ]
    }
   ],
   "source": [
    "model.init_sims(replace=True)  \n",
    "\n",
    "distance = model.wmdistance(s1, s2)\n",
    "print ('distance between s1 and s2 = %.4f' % distance)\n",
    "\n",
    "distance = model.wmdistance(s1, s3)\n",
    "print ('distance between s1 and s3 = %.4f' % distance)\n",
    "\n",
    "distance = model.wmdistance(s2, s3)\n",
    "print ('distance between s2 and s3 = %.4f' % distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Повторим тоже самое на корпусе твиттов [1]. \n",
    "\n",
    "Считываем данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tdate</th>\n",
       "      <th>tuser</th>\n",
       "      <th>ttext</th>\n",
       "      <th>ttype</th>\n",
       "      <th>trep</th>\n",
       "      <th>tfav</th>\n",
       "      <th>tstcount</th>\n",
       "      <th>tfol</th>\n",
       "      <th>tfriend</th>\n",
       "      <th>listcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>408906692374446080</td>\n",
       "      <td>1386325927</td>\n",
       "      <td>pleease_shut_up</td>\n",
       "      <td>@first_timee хоть я и школота, но поверь, у на...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7569</td>\n",
       "      <td>62</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>408906692693221377</td>\n",
       "      <td>1386325927</td>\n",
       "      <td>alinakirpicheva</td>\n",
       "      <td>Да, все-таки он немного похож на него. Но мой ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11825</td>\n",
       "      <td>59</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>408906695083954177</td>\n",
       "      <td>1386325927</td>\n",
       "      <td>EvgeshaRe</td>\n",
       "      <td>RT @KatiaCheh: Ну ты идиотка) я испугалась за ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1273</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>408906695356973056</td>\n",
       "      <td>1386325927</td>\n",
       "      <td>ikonnikova_21</td>\n",
       "      <td>RT @digger2912: \"Кто то в углу сидит и погибае...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1549</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>408906761416867842</td>\n",
       "      <td>1386325943</td>\n",
       "      <td>JumpyAlex</td>\n",
       "      <td>@irina_dyshkant Вот что значит страшилка :D\\nН...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>597</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id       tdate            tuser  \\\n",
       "0  408906692374446080  1386325927  pleease_shut_up   \n",
       "1  408906692693221377  1386325927  alinakirpicheva   \n",
       "2  408906695083954177  1386325927        EvgeshaRe   \n",
       "3  408906695356973056  1386325927    ikonnikova_21   \n",
       "4  408906761416867842  1386325943        JumpyAlex   \n",
       "\n",
       "                                               ttext  ttype  trep  tfav  \\\n",
       "0  @first_timee хоть я и школота, но поверь, у на...      1     0     0   \n",
       "1  Да, все-таки он немного похож на него. Но мой ...      1     0     0   \n",
       "2  RT @KatiaCheh: Ну ты идиотка) я испугалась за ...      1     0     1   \n",
       "3  RT @digger2912: \"Кто то в углу сидит и погибае...      1     0     1   \n",
       "4  @irina_dyshkant Вот что значит страшилка :D\\nН...      1     0     0   \n",
       "\n",
       "   tstcount   tfol  tfriend  listcount  \n",
       "0         0   7569       62         61  \n",
       "1         0  11825       59         31  \n",
       "2         0   1273       26         27  \n",
       "3         0   1549       19         17  \n",
       "4         0    597       16         23  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('/NLP/data/positive.csv', sep=';', header=None,  index_col = False,\n",
    "                  names = [ 'id', 'tdate', 'tuser', 'ttext', 'ttype',\n",
    "                          'trep', 'tfav', 'tstcount', 'tfol','tfriend', 'listcount'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предобработка (приводим к нижнему регистру, удаляем стоп-слова и некириллические символы):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regex = re.compile(\"[А-Яа-яё]+\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    return \" \".join(regex.findall(text))\n",
    "\n",
    "\n",
    "\n",
    "def  remove_stopwords(text, stopwords = stopwords.words('russian')):\n",
    "    try:\n",
    "        return \" \".join([token for token in text.split() if not token in stopwords])\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "raw_tweets = data.ttext.tolist()\n",
    "data.ttext = data.ttext.str.lower()\n",
    "data.ttext = data.ttext.apply(words_only)\n",
    "data.ttext = data.ttext.apply(remove_stopwords)   \n",
    "\n",
    "\n",
    "tweets = [tweet.split() for tweet in data.ttext.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем класс для вычисления близостей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.similarities import WmdSimilarity\n",
    "num_best = 10\n",
    "instance = WmdSimilarity(tweets, model, num_best=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задаем документ-запрос и предобрабатываем его:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 'Ученые обнаружили ископаемую ящерицу с парой теменных глаз'\n",
    "query = words_only(s1).lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поиск по запросу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = instance[query] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: ['ученые', 'обнаружили', 'ископаемую', 'ящерицу', 'с', 'парой', 'теменных', 'глаз']\n",
      "2401\n",
      "Ученые установили, что если пищу пережевывать, то давятся витамины, а если не пережевывать - люди.))\n",
      "\n",
      "12140\n",
      "@__cherry__bomb_ про девушку у которой врачи обнаружили рак .ну вообще интересный )))\n",
      "\n",
      "94458\n",
      "RT @jofutypobaty: Ученые скрестили гиену с пнем и получили гиенологическое дерево)))\n",
      "\n",
      "29935\n",
      "Американские ученые выяснили - в недосыпании детей виноваты родители -  http://t.co/NJXMM5DYrA А-а, это так ржачно, надо поделиться )))\n",
      "\n",
      "109592\n",
      "@RimVell всеееее, выкололи тебе этот глаз и пролезли в мозг!)\n",
      "\n",
      "46433\n",
      "читали? http://t.co/kVaartO6bfПортал:Ниасилили/t.A.T.u )) не в бровь, а в глаз,как говориться) всю статью можно растащить на цитаты)\n",
      "\n",
      "114425\n",
      "RT @VITAMIN_PERM: Сначала глаз сломался ... Потом и мозг треснул )))\n",
      " http://t.co/V6p6udMSQ4\n",
      "\n",
      "93210\n",
      "@Vladiysss мандаринку приложи,говорят помогает)\n",
      "Сразу глаз пройдёт\n",
      "\n",
      "56187\n",
      "@freiman @vodolady отлично,  завтра приду на работу с баклашкой со словами \"ученые доказали!\" ))))))))\n",
      "\n",
      "4092\n",
      "RT @LoL__Kate: @KirillPetryshko @Scream_Hater а то сидят много глаз )\n",
      "Не будем палиться )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Query:', query)\n",
    "for i in range(10):\n",
    "    print(sims[i][0])\n",
    "    print(raw_tweets[sims[i][0]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Источники \n",
    "1. Kusner, Matt, Yu Sun, Nicholas Kolkin, and Kilian Weinberger. \"From word embeddings to document distances.\" In International Conference on Machine Learning, pp. 957-966. 2015.\n",
    "2. Ю. В. Рубцова. Построение корпуса текстов для настройки тонового классификатора // Программные продукты и системы, 2015, №1(109), –С.72-78"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
