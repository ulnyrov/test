{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import bz2\n",
    "import regex\n",
    "from tqdm import tqdm\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "responses = []\n",
    "with bz2.BZ2File('banki_responses.json.bz2', 'r') as thefile:\n",
    "    for row in tqdm(thefile):\n",
    "        resp = json.loads(row)\n",
    "        if not resp['rating_not_checked'] and (len(resp['text'].split()) > 0):\n",
    "            responses.append(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Домашнее задание по NLP # 2 [100 баллов] \n",
    "## Составление словарей для классификации по тональности\n",
    "При классификации текстов или предложений по тональности необходимо использовать оценочные словари для предметной области, то есть, такие словари, в которых содержатся отрицательные и позитивные слова для какой-то предметной области. Идея подобных словарей основана на следующих наблюдениях: во-первых, для разных товаров используются разные оценочные слова (например бывает “захватывающая книга”, но не бывает “захватывающих лыж”), во-вторых, в контексте разных товаров одни и те же слова могут иметь разную окраску (слово “тормоз” в отзыве на велосипед имеет нейтральную окраску, в отзыве на компьютер – резко негативную, “пыль” в контексте пылесосов – нейтральную, в контексте кофемолок – положительную (“мелкий помол в пыль”)). Еще один пример: \"теплое пиво\" – это плохо, а \"теплый свитер\" – это хорошо.  \n",
    "\n",
    "Составление таких словарей в ручную – трудоемкий процесс, но, к счастью, его не сложно автоматизировать, если собрать достаточно большие корпуса отзывов. В этом домашнем задании вам предстоит попробовать реализовать один их подходов к составлению оценочных словарей, основанный на статье Inducing Domain-Specific Sentiment Lexicons from Unlabeled Corpora (https://nlp.stanford.edu/pubs/hamilton2016inducing.pdf).\n",
    "\n",
    "\n",
    "Данные для задания – уже знакомые вам отзывы на банки, собранные с нескольких сайтов Рунета. Отзывы могут быть как положительными (оценка 5), так и отрицательными (оценка 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses[99]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Обучение модели word2vec [50 баллов]\n",
    "\n",
    "1. Разбейте всю коллекцию отзывов на предложения. Лемматизируйте все слова. \n",
    "2. Обучите по коллекции предложений word2vec\n",
    "3. Приведите несколько удачных и неудачных примеров решения стандартных текстов для word2vec:\n",
    "    * тест на определение ближайших слов\n",
    "    * тест на аналогии (мужчина – король : женщина – королева)\n",
    "    * тест на определение лишнего слова.\n",
    "    \n",
    "4. Постройте несколько визуализаций:\n",
    "    * TSNE для топ-100 (или топ-500) слов и найдите осмысленные кластеры слов\n",
    "    * задайте координаты для нового пространства следующим образом: одна  ось описывает отношение \"плохо – хорошо\", вторая – \"медленно – быстро\" и найдите координаты названий банков в этих координатах.  Более формально:\n",
    "    берем вектор слова \"хорошо\", вычитаем из него вектор слова \"плохо\", получаем новый вектор, который описывает разницу между хорошими и плохими словами. Берем вектор слова \"сбербанк\" и умножаем его на этот новый вектор – получаем координату по первой оси. Аналогично – для второй оси. Две координаты уже можно нарисовать на плоскости.  \n",
    " \n",
    "\n",
    "\n",
    "Ссылка на примеры визуализаций: https://towardsdatascience.com/game-of-thrones-word-embeddings-does-r-l-j-part-2-30290b1c0b4b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Распространение метки [50 баллов]\n",
    "\n",
    "Определите 5-8 позитивных слов (например, “быстрый”, “удобный”) и 5-8  негативных слов (например,“очередь”, “медленно”). Эти слова будут основной будущего оценочного словаря. Пусть позитивному классу соответствует метка 1, негативному – -1. Пометьте выбранные слова в лексическом графе соответствующими метками. Запустите любой известный вам метод распространения метки (Label Propogation) в лексическом графе. На выходе метода распространения ошибки должны быть новые слова, помеченные метками 1 и -1 – это и есть искомые оценочные слова.\n",
    "\n",
    "Алгоритмы распространения метки устроены примерно так: пусть мы находимся в выршине, помеченном +1. С какой-то вероятностью мы переносим эту метку на соседние узлы. С меньшей вероятностью переносим ее на вершины на расстоянии два. В конце распространения метки, часть вершин оказывается помечена меткой +1, часть – -1, большая часть остается без метки.\n",
    "\n",
    "Рекомендуемые алгоритмы распространения метки:\n",
    "1. ```graphlab.label_propagation``` (```graphlab``` доступен бесплатно по образовательной лицензии)\n",
    "2. ```sklearn.semi_supervised.LabelPropagation``` \n",
    "3. ```sklearn.semi_supervised.LabelSpreading```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пример построения графа \n",
    "\n",
    "import igraph as ig\n",
    "g = ig.Graph(directed=True)\n",
    "for word in model.wv.vocab.keys():\n",
    "    g.add_vertex(word)\n",
    "    \n",
    "    \n",
    "    \n",
    "for word in model.wv.vocab.keys() :\n",
    "    node = g.vs.select(name = word).indices[0]\n",
    "    similar_words = model.most_similar(word, topn=5)\n",
    "    for sim in similar_words:\n",
    "        word1 = sim[0]\n",
    "        val  = sim[1]\n",
    "        new_node = g.vs.select(name = word1).indices[0]\n",
    "        g.add_edge(node, new_node, weight = val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
